{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cleaning\" data-toc-modified-id=\"Cleaning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cleaning</a></span></li><li><span><a href=\"#Pipeline\" data-toc-modified-id=\"Pipeline-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pipeline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Categorical-features\" data-toc-modified-id=\"Categorical-features-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Categorical features</a></span></li><li><span><a href=\"#Binary-features\" data-toc-modified-id=\"Binary-features-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Binary features</a></span></li><li><span><a href=\"#Numerical-features\" data-toc-modified-id=\"Numerical-features-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Numerical features</a></span></li><li><span><a href=\"#preprocessing-pipe\" data-toc-modified-id=\"preprocessing-pipe-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>preprocessing pipe</a></span></li><li><span><a href=\"#output-processing\" data-toc-modified-id=\"output-processing-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>output processing</a></span></li><li><span><a href=\"#regression-model\" data-toc-modified-id=\"regression-model-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>regression model</a></span></li></ul></li><li><span><a href=\"#Training-and-evaluation\" data-toc-modified-id=\"Training-and-evaluation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training and evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mean-regressor-baseline\" data-toc-modified-id=\"Mean-regressor-baseline-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Mean regressor baseline</a></span></li><li><span><a href=\"#Cross-validation\" data-toc-modified-id=\"Cross-validation-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Cross validation</a></span></li><li><span><a href=\"#Valid-evaluation\" data-toc-modified-id=\"Valid-evaluation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Valid evaluation</a></span></li><li><span><a href=\"#Train-evaluation\" data-toc-modified-id=\"Train-evaluation-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Train evaluation</a></span></li><li><span><a href=\"#Error-analysis\" data-toc-modified-id=\"Error-analysis-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Error analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#over-estimated\" data-toc-modified-id=\"over-estimated-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>over estimated</a></span></li><li><span><a href=\"#under-estimated\" data-toc-modified-id=\"under-estimated-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>under estimated</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (StandardScaler, LabelEncoder, PolynomialFeatures,\n",
    "                                   OneHotEncoder, OrdinalEncoder, FunctionTransformer,\n",
    "                                   PowerTransformer)\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from joblib import dump, load\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!../scrapper/scrapper.py csv --file ./fulltrain.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = read_csv('fulltrain.csv', index_col='idannonce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chauffageNArows = df_full['idtypechauffage'] == 0\n",
    "df_full.loc[chauffageNArows,'idtypechauffage'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codpostal33rows = df_full['codepostal'] == 33\n",
    "df_full.loc[codpostal33rows,'codepostal'] = 33000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisineNArows = df_full['idtypecuisine'] == 0\n",
    "df_full.loc[cuisineNArows,'idtypecuisine'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['surface'] = df_full['surface'].str.replace(\",\", \".\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_surface = df_full['surface'] != 0\n",
    "df_full = df_full.loc[nonzero_surface,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notcolocation_rows = ~(df_full['description'].str.contains(\"([Cc]oloc)\")).astype('Bool')\n",
    "df_full = df_full.loc[notcolocation_rows,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.drop(['id','ville', 'codeinsee','nb_photos', 'dpeL', 'description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_full.to_csv('dataset_clean.csv', header=True, index_label=id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categoricals = ['typedebien', 'ville','idtypechauffage', 'idtypecuisine','codepostal','codeinsee']\n",
    "categoricals = ['typedebien', 'idtypechauffage', 'idtypecuisine', 'codepostal']\n",
    "binaries = ['si_balcon','si_sdbain','si_sdEau']\n",
    "#numericals = ['nb_chambres', 'nb_pieces', 'nb_photos', 'etage', 'surface', 'dpeC']\n",
    "numericals = ['nb_chambres', 'nb_pieces', 'etage', 'surface', 'dpeC']\n",
    "text = ['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categoricals:\n",
    "    print(df_full[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in binaries:\n",
    "    print(df_full[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    #('poly', PolynomialFeatures(degree=2)),\n",
    "    ('power',  PowerTransformer()),\n",
    "    #('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipe = ColumnTransformer([\n",
    "    ('cat', categorical_pipe, categoricals),\n",
    "    ('num', numerical_pipe, numericals),\n",
    "    ('ord', binary_pipe, binaries)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pipe = Pipeline([\n",
    "    ('log', FunctionTransformer(func=np.log, inverse_func=np.exp)),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdgRegressor = Ridge()\n",
    "xgbRegressor = XGBRegressor(booster=\"gbtree\")\n",
    "svrRegressor = SVR(kernel='rbf', C=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('pre', preprocess_pipe),\n",
    "    ('reg', svrRegressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipe = TransformedTargetRegressor(regressor=model, transformer=output_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(full_pipe,'pipeline-model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target_column = \"prix\"\n",
    "\n",
    "X_fulltrain = df_full.drop(target_column, axis=1)\n",
    "y_fulltrain = df_full[target_column]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_fulltrain, y_fulltrain, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipe.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean regressor baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = [np.mean(y_train)] * y_valid.shape[0]\n",
    "r2 = r2_score(y_valid, y_valid_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
    "rmsle = np.sqrt(mean_squared_error(np.log(y_valid), np.log(y_valid_pred)))\n",
    "msle = (mean_squared_error(np.log(y_valid), np.log(y_valid_pred)))\n",
    "mape = np.mean(np.abs((y_valid-y_valid_pred)/y_valid))\n",
    "print(f'r2 = {r2}\\nrmse = {rmse}\\nmsle = {msle}\\nrmsle = {rmsle}\\nmape = {mape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(full_pipe, X_fulltrain, y=y_fulltrain, cv=10)\n",
    "print(f'mean R2 = {np.mean(scores)} +/- {np.std(scores)}')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = full_pipe.predict(X_valid)\n",
    "r2 = r2_score(y_valid, y_valid_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
    "rmsle = np.sqrt(mean_squared_error(np.log(y_valid), np.log(y_valid_pred)))\n",
    "msle = (mean_squared_error(np.log(y_valid), np.log(y_valid_pred)))\n",
    "mape = np.mean(np.abs((y_valid-y_valid_pred)/y_valid))\n",
    "print(f'r2 = {r2}\\nrmse = {rmse}\\nmsle = {msle}\\nrmsle = {rmsle}\\nmape = {mape}')\n",
    "grid = sns.JointGrid(y_valid, y_valid_pred)\n",
    "grid = grid.plot(sns.regplot, sns.distplot)\n",
    "grid.ax_joint.plot([0,2500], [0,2500], 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = full_pipe.predict(X_train)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "rmsle = np.sqrt(mean_squared_error(np.log(y_train), np.log(y_train_pred)))\n",
    "msle = (mean_squared_error(np.log(y_train), np.log(y_train_pred)))\n",
    "mape = np.mean(np.abs((y_train-y_train_pred)/y_train))\n",
    "print(f'r2 = {r2}\\nrmse = {rmse}\\nmsle = {msle}\\nrmsle = {rmsle}\\nmape = {mape}')\n",
    "grid = sns.JointGrid(y_train, y_train_pred)\n",
    "grid = grid.plot(sns.regplot, sns.distplot)\n",
    "grid.ax_joint.plot([0,2500], [0,2500], 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.JointGrid(y_valid, (y_valid_pred-y_valid)/y_valid )\n",
    "grid = grid.plot(sns.regplot, sns.distplot)\n",
    "grid.ax_joint.plot([0,2500], [0,0], 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### over estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors = ((y_valid_pred-y_valid)/y_valid) > 0.5\n",
    "error_df = X_valid.loc[errors,:]\n",
    "error_df.loc[errors,'prix'] = y_valid.loc[errors]\n",
    "error_df.loc[errors,'pred'] = y_valid_pred[errors]\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### under estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = (y_valid_pred-y_valid)/y_valid < -0.4\n",
    "error_df = X_valid.loc[errors,:]\n",
    "error_df.loc[errors,'prix'] = y_valid.loc[errors]\n",
    "error_df.loc[errors,'pred'] = y_valid_pred[errors]\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_str =  str(datetime.now()).replace(' ', '_')\n",
    "model_file_name = 'realestate-model-' + now_str + '.pkl'\n",
    "model_dir = './'\n",
    "model_dir + model_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(full_pipe, model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "max(glob('realestate-model-*.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
