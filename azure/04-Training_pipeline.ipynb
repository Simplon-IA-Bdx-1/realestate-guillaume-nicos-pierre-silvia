{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Environment</a></span></li><li><span><a href=\"#Compute-Target-and-container\" data-toc-modified-id=\"Compute-Target-and-container-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Compute Target and container</a></span></li><li><span><a href=\"#Cleaning-step\" data-toc-modified-id=\"Cleaning-step-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cleaning step</a></span></li><li><span><a href=\"#Pipeline\" data-toc-modified-id=\"Pipeline-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Pipeline</a></span></li><li><span><a href=\"#Run-pipeline\" data-toc-modified-id=\"Run-pipeline-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Run pipeline</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.core import Workspace, Datastore, Dataset\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.core import Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "steps_dir = './pipeline_steps'\n",
    "cpu_cluster_name = \"cpucluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Target and container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "cpu_cluster.wait_for_completion(show_output=True)\n",
    "\n",
    "# Create a new runconfig object\n",
    "run_amlcompute = RunConfiguration()\n",
    "\n",
    "# Use the cpu_cluster you created above. \n",
    "run_amlcompute.target = cpu_cluster\n",
    "\n",
    "# Enable Docker\n",
    "run_amlcompute.environment.docker.enabled = True\n",
    "\n",
    "# Set Docker base image to the default CPU-based image\n",
    "run_amlcompute.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "run_amlcompute.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Specify CondaDependencies obj, add necessary packages\n",
    "pip_packages=['azureml-dataprep[fuse,pandas]',\n",
    "              'azureml.core']\n",
    "conda_packages=['scikit-learn==0.22',\n",
    "                'pandas==0.24.2',\n",
    "                'pyarrow==0.16.0'\n",
    "               ]\n",
    "run_amlcompute.environment.python.conda_dependencies = CondaDependencies.create(python_version='3.7.7',\n",
    "                                                                                pip_packages=pip_packages,\n",
    "                                                                                conda_packages=conda_packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = Dataset.get_by_name(ws, name=\"annonces_ds\")\n",
    "\n",
    "clean_ds = PipelineData(\"dataset_clean\",\n",
    "                        datastore=def_blob_store).as_dataset().parse_delimited_files()\n",
    "#clean_ds = clean_ds.register()\n",
    "\n",
    "clean_step = PythonScriptStep(\n",
    "    script_name=\"clean.py\",\n",
    "    arguments=[\"--input\", dataset_full.name, \"--output\", clean_ds],\n",
    "    inputs=[dataset_full.as_named_input(dataset_full.name)],\n",
    "    outputs=[clean_ds],\n",
    "    compute_target=cpu_cluster,\n",
    "    runconfig=run_amlcompute,\n",
    "    source_directory=steps_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PipelineData(\"dataset_train\",\n",
    "                        datastore=def_blob_store).as_dataset().parse_delimited_files()\n",
    "valid_ds = PipelineData(\"dataset_valid\",\n",
    "                        datastore=def_blob_store).as_dataset().parse_delimited_files()\n",
    "\n",
    "train_size = PipelineParameter(\n",
    "  name=\"Train_Size\",\n",
    "  default_value=800)\n",
    "\n",
    "valid_size = PipelineParameter(\n",
    "  name=\"ValidSize\",\n",
    "  default_value=200)\n",
    "\n",
    "split_step = PythonScriptStep(\n",
    "    script_name=\"split.py\",\n",
    "    arguments=[\n",
    "        \"--dataset\", clean_ds,\n",
    "        \"--train\", train_ds,\n",
    "        \"--valid\", valid_ds,\n",
    "        \"--trainsize\", train_size,\n",
    "        \"--validsize\", valid_size\n",
    "    ],\n",
    "    inputs=[clean_ds],\n",
    "    outputs=[train_ds, valid_ds],\n",
    "    compute_target=cpu_cluster,\n",
    "    runconfig=run_amlcompute,\n",
    "    source_directory=steps_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = PipelineData(\n",
    "    \"model\",\n",
    "    datastore=def_blob_store\n",
    ")#.as_download(input_name=\"model.pkl\", path_on_compute='./')\n",
    "\n",
    "train_step = PythonScriptStep(\n",
    "    script_name=\"train.py\",\n",
    "    arguments=[\n",
    "        \"--dataset\", train_ds,\n",
    "        \"--model\", trained_model\n",
    "    ],\n",
    "    inputs=[train_ds],\n",
    "    outputs=[trained_model],\n",
    "    compute_target=cpu_cluster,\n",
    "    runconfig=run_amlcompute,\n",
    "    source_directory=steps_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_step = PythonScriptStep(\n",
    "    script_name=\"eval.py\",\n",
    "    arguments=[\n",
    "        \"--dataset\", valid_ds,\n",
    "        \"--model\", trained_model.name\n",
    "    ],\n",
    "    inputs=[valid_ds,\n",
    "            trained_model],\n",
    "    compute_target=cpu_cluster,\n",
    "    runconfig=run_amlcompute,\n",
    "    source_directory=steps_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = Pipeline(workspace=ws, steps=[clean_step, split_step, train_step, eval_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step clean.py [4c27f273][9cffc60b-fc4f-4b38-b834-4dbb554a55fa], (This step will run and generate new outputs)Created step split.py [001ae348][577764fc-630c-4ef6-b1c6-31f964f2226d], (This step will run and generate new outputs)\n",
      "\n",
      "Created step train.py [d1d2310d][c9d92338-769b-4adc-8497-cbd343253240], (This step will run and generate new outputs)\n",
      "Created step eval.py [2ec79550][e663af80-2d1b-4ae5-aa63-dc40dca74767], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 892ebe57-d526-4412-933f-15b596de903f\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/TrainingPipeline/runs/892ebe57-d526-4412-933f-15b596de903f?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n"
     ]
    }
   ],
   "source": [
    "pipeline_run = Experiment(ws, 'TrainingPipeline').submit(train_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 892ebe57-d526-4412-933f-15b596de903f\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/TrainingPipeline/runs/892ebe57-d526-4412-933f-15b596de903f?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: aa4cb714-98ea-4946-8ee2-98d520f42968\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/TrainingPipeline/runs/aa4cb714-98ea-4946-8ee2-98d520f42968?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "StepRun( clean.py ) Status: NotStarted\n",
      "StepRun( clean.py ) Status: Queued\n",
      "StepRun( clean.py ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_c28e972a09d951131dd68c43762d6835bc1a89decf530156d552579d1b9d1186_d.txt\n",
      "========================================================================================================================\n",
      "2020-04-03T13:56:06Z Starting output-watcher...\n",
      "2020-04-03T13:56:06Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_c30f0e4e66ae5a324014f63a272f7ba7\n",
      "Digest: sha256:ea753b74af41e7144b92336e1aa829a7b89e4ed5aa8e1419f322d6c02da9a14d\n",
      "Status: Image is up to date for realestatepg7d804713.azurecr.io/azureml/azureml_c30f0e4e66ae5a324014f63a272f7ba7:latest\n",
      "567ba225b2d744e900c4637a90d27aefb886f52c01ef45a69cd249b78dfd9207\n",
      "2020/04/03 13:56:12 Version: 3.0.01172.0001 Branch: master Commit: d33e301a\n",
      "2020/04/03 13:56:13 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/04/03 13:56:13 sshd runtime has already been installed in the container\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_c28e972a09d951131dd68c43762d6835bc1a89decf530156d552579d1b9d1186_d.txt\n",
      "===============================================================================================================\n",
      "Starting job preparation. Current time:2020-04-03T13:56:24.504009\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n"
     ]
    }
   ],
   "source": [
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline_run.register_model(model_name='FirstModel', model_path='outputs/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.publish_pipeline(\n",
    "     name=\"Training_pipeline\",\n",
    "     description=\"This is a training pipeline for the realestate project\",\n",
    "     version=\"1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Published Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "\n",
    "cli_auth = AzureCliAuthentication()\n",
    "aad_token = cli_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PublishedPipeline\n",
    "import requests\n",
    "\n",
    "response = requests.post(train_pipeline.endpoint,\n",
    "                         headers=aad_token,\n",
    "                         json={\"ExperimentName\": \"Training\",\n",
    "                               \"ParameterAssignments\": {\"Train_Size\": 800,\n",
    "                                                        \"Valid_Size\": 200}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
