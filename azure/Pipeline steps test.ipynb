{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "from azureml.core import ScriptRunConfig, RunConfiguration, Experiment\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.data.data_reference import DataReference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "def_file_store = Datastore(ws, \"workspacefilestore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing clean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'use_docker' parameter will be deprecated. Please use 'environment_definition' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: CleanTest_1585813664_058ca633\n",
      "Web View: https://ml.azure.com/experiments/CleanTest/runs/CleanTest_1585813664_058ca633?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 92\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ pipeline_steps/clean.py ] with arguments: ['--input', 'annonces_ds', '--output', 'cleantest']\n",
      "After variable expansion, calling script [ pipeline_steps/clean.py ] with arguments: ['--input', 'annonces_ds', '--output', 'cleantest']\n",
      "\n",
      "/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py:722: UserWarning: Your pandas and pyarrow versions are incompatible. Please install pyarrow>=0.12.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install azureml-dataprep[pandas].\n",
      "  warnings.warn('Your pandas and pyarrow versions are incompatible. '\n",
      "/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/python3.6/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 92\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.8115854263305664 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: CleanTest_1585813664_058ca633\n",
      "Web View: https://ml.azure.com/experiments/CleanTest/runs/CleanTest_1585813664_058ca633?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'CleanTest_1585813664_058ca633',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-04-02T07:47:47.59181Z',\n",
       " 'endTimeUtc': '2020-04-02T07:49:07.669134Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'c0f5c2a8-e300-478f-86d0-e39126f72781'},\n",
       " 'inputDatasets': [{'dataset': {'id': '5a88c2bd-5165-485b-a81f-bc8290270b5a'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'annonces_ds', 'mechanism': 'Direct'}}],\n",
       " 'runDefinition': {'script': 'pipeline_steps/clean.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input', 'annonces_ds', '--output', 'cleantest'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'annonces_ds': {'dataLocation': {'dataset': {'id': '5a88c2bd-5165-485b-a81f-bc8290270b5a'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'annonces_ds',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment CleanTest Environment',\n",
       "   'version': 'Autosave_2020-04-02T07:45:21Z_0ac19a9a',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}],\n",
       "     'name': 'azureml_da3e97fcb51801118b8e80207f3e01ad'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585813664_058ca633/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=mv1Wm3EY7cyPX3WctNr3uniMm3oSym7gXGzNm%2FWNxOU%3D&st=2020-04-02T07%3A36%3A45Z&se=2020-04-02T15%3A46%3A45Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585813664_058ca633/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=e9z1EchoZLCi1Ln4Y5CKbIutwc9qcZbHC750KK4twAg%3D&st=2020-04-02T07%3A36%3A45Z&se=2020-04-02T15%3A46%3A45Z&sp=r',\n",
       "  'logs/azureml/92_azureml.log': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585813664_058ca633/logs/azureml/92_azureml.log?sv=2019-02-02&sr=b&sig=tjCXtD2aHs9uID5u0%2Bp%2B8iQoX56L%2FasmRKhG019agzU%3D&st=2020-04-02T07%3A36%3A45Z&se=2020-04-02T15%3A46%3A45Z&sp=r'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(ws, name='annonces_ds')\n",
    "experiment = Experiment(ws, \"CleanTest\")\n",
    "\n",
    "clean_est = Estimator(source_directory='.', entry_script='./pipeline_steps/clean.py',\n",
    "                script_params= {\"--input\": 'annonces_ds', \"--output\": 'cleantest'},\n",
    "                inputs=[dataset.as_named_input('annonces_ds')],\n",
    "                compute_target='local',\n",
    "                use_docker=False\n",
    "               )\n",
    "\n",
    "run = experiment.submit(clean_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",idannonce,typedebien,codepostal,idtypechauffage,idtypecuisine,si_balcon,nb_chambres,nb_pieces,si_sdbain,si_sdEau,etage,prix,surface,dpeC,date\r\n",
      "0,154680523,Appartement,33000,gaz collectif,,0.0,2.0,3,1,0,2.0,843,60.0,0.0,2019-03-28 15:30:41.565724000\r\n",
      "1,155037587,Appartement,33700,individuel électrique radiateur,aucune,0.0,0.0,1,0,0,2.0,512,21.35,195.0,2019-03-28 19:37:48.081944028\r\n",
      "2,152350643,Appartement,33140,,,1.0,2.0,3,0,0,3.0,859,69.48,138.0,2019-03-28 23:44:54.598164056\r\n",
      "3,155513075,Appartement,33400,,,1.0,1.0,2,0,0,3.0,695,47.25,162.0,2019-03-29 03:52:01.114384084\r\n",
      "4,155025785,Appartement,33000,gaz collectif,,0.0,2.0,3,1,0,4.0,814,68.0,0.0,2019-03-29 07:59:07.630604112\r\n",
      "5,155551059,Appartement,33700,individuel électrique,américaine,1.0,2.0,3,1,0,0.0,756,65.51,0.0,2019-03-29 12:06:14.146824141\r\n",
      "7,154854333,Appartement,33600,,équipée,0.0,1.0,2,0,1,0.0,720,36.0,0.0,2019-03-29 20:20:27.179264197\r\n",
      "8,155325225,Appartement,33600,individuel,,1.0,1.0,2,0,1,1.0,564,37.01,167.0,2019-03-30 00:27:33.695484225\r\n",
      "10,153924329,Appartement,33150,individuel gaz radiateur,équipée,0.0,2.0,3,1,0,0.0,763,73.09,45.0,2019-03-30 08:41:46.727924282\r\n"
     ]
    }
   ],
   "source": [
    "run.download_file('outputs/cleantest', output_file_path='./cleantmp.csv')\n",
    "!head ./cleantmp.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./cleantmp.csv\n",
      "Uploaded ./cleantmp.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "clean_ref = def_blob_store.upload_files(\n",
    "    ['./cleantmp.csv'],\n",
    "    target_path='tmp/clean.csv',\n",
    "    overwrite=True)\n",
    "clean_ref.data_reference_name = \"clean_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_est = Estimator(source_directory='./pipeline_steps', entry_script='split.py',\n",
    "                script_params= {\"--dataset\": \"clean_data\",\n",
    "                                \"--train\" \"train_ds\",\n",
    "                                \"--valid\" \"valid_ds\",\n",
    "                                \"--trainsize\" 400,\n",
    "                                \"--validsize\" 100},\n",
    "                inputs=[clean_ref],\n",
    "                compute_target='local',\n",
    "                use_docker=False\n",
    "               )\n",
    "\n",
    "run = experiment.submit(split_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.download_file('outputs/train_ds', output_file_path='./train_dstmp.csv')\n",
    "!head ./cleantmp.csv\n",
    "run.download_file('outputs/valid_ds', output_file_path='./valid_dstmp.csv')\n",
    "!head ./cleantmp.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ref = def_blob_store.upload_files(\n",
    "    ['./train_dstmp.csv'],\n",
    "    target_path='tmp/train.csv',\n",
    "    overwrite=True)\n",
    "train_ref.data_reference_name = \"train_data\"\n",
    "\n",
    "valid_ref = def_blob_store.upload_files(\n",
    "    ['./valid_dstmp.csv'],\n",
    "    target_path='tmp/valid.csv',\n",
    "    overwrite=True)\n",
    "valid_ref.data_reference_name = \"valid_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_est = Estimator(source_directory='.', entry_script='./pipeline_steps/train.py',\n",
    "                script_params= {\"--dataset\": \"train_data\",\n",
    "                                \"--model\": \"model.pkl\"},\n",
    "                inputs=[train_ref],\n",
    "                compute_target='local',\n",
    "                use_docker=False\n",
    "               )\n",
    "\n",
    "run = experiment.submit(split_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name='test_model',\n",
    "                           tags={'test': 'test'},\n",
    "                           model_path='outputs/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_est = Estimator(source_directory='.', entry_script='./pipeline_steps/eval.py',\n",
    "                script_params= {\"--dataset\": \"valid_data\",\n",
    "                                \"--model\": \"model.pkl\"},\n",
    "                inputs=[valid_ref],\n",
    "                compute_target='local',\n",
    "                use_docker=False\n",
    "               )\n",
    "\n",
    "run = experiment.submit(eval_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
