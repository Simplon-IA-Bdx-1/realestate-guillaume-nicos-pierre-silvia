{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "from azureml.core import ScriptRunConfig, RunConfiguration, Experiment\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.data.data_reference import DataReference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "def_file_store = Datastore(ws, \"workspacefilestore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing clean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'use_docker' parameter will be deprecated. Please use 'environment_definition' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: CleanTest_1585823600_183b9301\n",
      "Web View: https://ml.azure.com/experiments/CleanTest/runs/CleanTest_1585823600_183b9301?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 669\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ clean.py ] with arguments: ['--input', 'annonces_ds', '--output', 'cleantest']\n",
      "After variable expansion, calling script [ clean.py ] with arguments: ['--input', 'annonces_ds', '--output', 'cleantest']\n",
      "\n",
      "/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py:722: UserWarning: Your pandas and pyarrow versions are incompatible. Please install pyarrow>=0.12.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install azureml-dataprep[pandas].\n",
      "  warnings.warn('Your pandas and pyarrow versions are incompatible. '\n",
      "/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/python3.6/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 669\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.9992814064025879 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: CleanTest_1585823600_183b9301\n",
      "Web View: https://ml.azure.com/experiments/CleanTest/runs/CleanTest_1585823600_183b9301?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'CleanTest_1585823600_183b9301',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-04-02T10:33:21.356673Z',\n",
       " 'endTimeUtc': '2020-04-02T10:34:42.11558Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '187c48e4-92c4-4d8b-9222-b9ec642f942d'},\n",
       " 'inputDatasets': [{'dataset': {'id': '5a88c2bd-5165-485b-a81f-bc8290270b5a'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'annonces_ds', 'mechanism': 'Direct'}}],\n",
       " 'runDefinition': {'script': 'clean.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input', 'annonces_ds', '--output', 'cleantest'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'annonces_ds': {'dataLocation': {'dataset': {'id': '5a88c2bd-5165-485b-a81f-bc8290270b5a'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'annonces_ds',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment CleanTest Environment',\n",
       "   'version': 'Autosave_2020-04-02T07:45:21Z_0ac19a9a',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}],\n",
       "     'name': 'azureml_da3e97fcb51801118b8e80207f3e01ad'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585823600_183b9301/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=oV%2FPbvCYRNm6Kic1JFgG2c1ZaB05WsSNQxIJhbQxHrg%3D&st=2020-04-02T10%3A22%3A19Z&se=2020-04-02T18%3A32%3A19Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585823600_183b9301/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=Y5NLt8Vgw0Eijei6jUiiQtf9UR8DQBL2xYK3bWFMmCE%3D&st=2020-04-02T10%3A22%3A19Z&se=2020-04-02T18%3A32%3A19Z&sp=r',\n",
       "  'logs/azureml/669_azureml.log': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585823600_183b9301/logs/azureml/669_azureml.log?sv=2019-02-02&sr=b&sig=nWSn0%2F%2FA1RYy1XJbiG6l9wSJRLQ81JuvSmadStzU5gY%3D&st=2020-04-02T10%3A22%3A19Z&se=2020-04-02T18%3A32%3A19Z&sp=r'}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(ws, name='annonces_ds')\n",
    "experiment = Experiment(ws, \"CleanTest\")\n",
    "\n",
    "clean_est = Estimator(source_directory='./pipeline_steps', entry_script='clean.py',\n",
    "                script_params= {\"--input\": 'annonces_ds', \"--output\": 'cleantest'},\n",
    "                inputs=[dataset.as_named_input('annonces_ds')],\n",
    "                compute_target='local',\n",
    "                use_docker=False\n",
    "               )\n",
    "\n",
    "run = experiment.submit(clean_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",idannonce,typedebien,codepostal,idtypechauffage,idtypecuisine,si_balcon,nb_chambres,nb_pieces,si_sdbain,si_sdEau,etage,prix,surface,dpeC,date\r\n",
      "0,154680523,Appartement,33000,gaz collectif,,0.0,2.0,3,1,0,2.0,843,60.0,0.0,2019-03-28 15:30:41.565724000\r\n",
      "1,155037587,Appartement,33700,individuel électrique radiateur,aucune,0.0,0.0,1,0,0,2.0,512,21.35,195.0,2019-03-28 19:37:48.081944028\r\n",
      "2,152350643,Appartement,33140,,,1.0,2.0,3,0,0,3.0,859,69.48,138.0,2019-03-28 23:44:54.598164056\r\n",
      "3,155513075,Appartement,33400,,,1.0,1.0,2,0,0,3.0,695,47.25,162.0,2019-03-29 03:52:01.114384084\r\n",
      "4,155025785,Appartement,33000,gaz collectif,,0.0,2.0,3,1,0,4.0,814,68.0,0.0,2019-03-29 07:59:07.630604112\r\n",
      "5,155551059,Appartement,33700,individuel électrique,américaine,1.0,2.0,3,1,0,0.0,756,65.51,0.0,2019-03-29 12:06:14.146824141\r\n",
      "7,154854333,Appartement,33600,,équipée,0.0,1.0,2,0,1,0.0,720,36.0,0.0,2019-03-29 20:20:27.179264197\r\n",
      "8,155325225,Appartement,33600,individuel,,1.0,1.0,2,0,1,1.0,564,37.01,167.0,2019-03-30 00:27:33.695484225\r\n",
      "10,153924329,Appartement,33150,individuel gaz radiateur,équipée,0.0,2.0,3,1,0,0.0,763,73.09,45.0,2019-03-30 08:41:46.727924282\r\n"
     ]
    }
   ],
   "source": [
    "run.download_file('outputs/cleantest', output_file_path='./cleantmp.csv')\n",
    "!head ./cleantmp.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./cleantmp.csv\n",
      "Uploaded ./cleantmp.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "clean_ref = def_blob_store.upload_files(\n",
    "    ['./cleantmp.csv'],\n",
    "    target_path='tmp/clean.csv',\n",
    "    overwrite=True)\n",
    "clean_ref.data_reference_name = \"clean_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_paths = [(def_blob_store, 'tmp/clean.csv')]\n",
    "clan_ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)\n",
    "clan_ds = clan_ds.register(workspace=ws,\n",
    "                           name='clean_ds',\n",
    "                           description='annonces data clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'use_docker' parameter will be deprecated. Please use 'environment_definition' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: CleanTest_1585824735_84c9dfdf\n",
      "Web View: https://ml.azure.com/experiments/CleanTest/runs/CleanTest_1585824735_84c9dfdf?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 904\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ split.py ] with arguments: ['--dataset', 'clean_data', '--train', 'train_ds', '--valid', 'valid_ds', '--trainsize', '400', '--validsize', '100']\n",
      "After variable expansion, calling script [ split.py ] with arguments: ['--dataset', 'clean_data', '--train', 'train_ds', '--valid', 'valid_ds', '--trainsize', '400', '--validsize', '100']\n",
      "\n",
      "\n",
      "\n",
      "The experiment failed. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 904\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "1 items cleaning up...\n",
      "Cleanup took 0.3871300220489502 seconds\n",
      "Traceback (most recent call last):\n",
      "  File \"azureml-setup/context_manager_injector.py\", line 251, in <module>\n",
      "    execute_with_context(cm_objects, options.invocation)\n",
      "  File \"azureml-setup/context_manager_injector.py\", line 127, in execute_with_context\n",
      "    runpy.run_path(sys.argv[0], globals(), run_name=\"__main__\")\n",
      "  File \"/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/python3.6/runpy.py\", line 261, in run_path\n",
      "    code, fname = _get_code_from_file(run_name, path_name)\n",
      "  File \"/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/python3.6/runpy.py\", line 236, in _get_code_from_file\n",
      "    code = compile(f.read(), fname, 'exec')\n",
      "  File \"split.py\", line 33\n",
      "    print('Dataset: ' {}.format(input_dataset))\n",
      "                      ^\n",
      "SyntaxError: invalid syntax\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_est = Estimator(source_directory='./pipeline_steps',\n",
    "                      entry_script='split.py',\n",
    "                      script_params= {\"--dataset\": \"clean_data\",\n",
    "                                      \"--train\": \"train_ds\",\n",
    "                                      \"--valid\": \"valid_ds\",\n",
    "                                      \"--trainsize\": 400,\n",
    "                                      \"--validsize\": 100},\n",
    "                      #inputs=[clean_ref],\n",
    "                      inputs=[dataset.as_named_input('clean_ds')],\n",
    "                      compute_target='local',\n",
    "                      use_docker=False\n",
    "                     )\n",
    "\n",
    "run = experiment.submit(split_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DELIM',\n",
       " 'EXPERIMENT_PATH',\n",
       " 'RUN_PATH',\n",
       " 'RUN_TYPE',\n",
       " 'WORKSPACE_FMT',\n",
       " '_RUNSOURCE_PROPERTY',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_cancel_local',\n",
       " '_cleanup',\n",
       " '_client',\n",
       " '_container',\n",
       " '_context_manager',\n",
       " '_create',\n",
       " '_current_details',\n",
       " '_download_artifact_contents_to_string',\n",
       " '_download_working_directory',\n",
       " '_dto_to_run',\n",
       " '_experiment',\n",
       " '_experiment_url',\n",
       " '_from_run_dto',\n",
       " '_get_base_info_dict',\n",
       " '_get_blob_azureml_datastore',\n",
       " '_get_last_log_primary_instance',\n",
       " '_get_logs',\n",
       " '_get_outputs_datapath',\n",
       " '_get_portal_domain',\n",
       " '_get_process_status',\n",
       " '_heartbeat',\n",
       " '_identity',\n",
       " '_input_datasets',\n",
       " '_kill',\n",
       " '_load_scope',\n",
       " '_log_context',\n",
       " '_logger',\n",
       " '_output_logs_pattern',\n",
       " '_outputs',\n",
       " '_parse_process_files',\n",
       " '_portal_url',\n",
       " '_project_object',\n",
       " '_register_kill_handler',\n",
       " '_registered_kill_handlers',\n",
       " '_rehydrate_runs',\n",
       " '_repr_html_',\n",
       " '_root_run_id',\n",
       " '_run_config',\n",
       " '_run_config_object',\n",
       " '_run_details_url',\n",
       " '_run_dto',\n",
       " '_run_id',\n",
       " '_run_name',\n",
       " '_run_number',\n",
       " '_run_source',\n",
       " '_run_source_initializers',\n",
       " '_runtype',\n",
       " '_start_logging',\n",
       " '_stream_run_output',\n",
       " '_update_dataset_lineage',\n",
       " '_workspace_url',\n",
       " 'add_properties',\n",
       " 'add_type_provider',\n",
       " 'cancel',\n",
       " 'child_run',\n",
       " 'clean',\n",
       " 'complete',\n",
       " 'create_children',\n",
       " 'download_file',\n",
       " 'download_files',\n",
       " 'experiment',\n",
       " 'fail',\n",
       " 'flush',\n",
       " 'get_all_logs',\n",
       " 'get_children',\n",
       " 'get_context',\n",
       " 'get_details',\n",
       " 'get_details_with_logs',\n",
       " 'get_docs_url',\n",
       " 'get_environment',\n",
       " 'get_file_names',\n",
       " 'get_metrics',\n",
       " 'get_portal_url',\n",
       " 'get_properties',\n",
       " 'get_secret',\n",
       " 'get_secrets',\n",
       " 'get_snapshot_id',\n",
       " 'get_status',\n",
       " 'get_submitted_run',\n",
       " 'get_tags',\n",
       " 'id',\n",
       " 'identity',\n",
       " 'input_datasets',\n",
       " 'list',\n",
       " 'list_by_compute',\n",
       " 'log',\n",
       " 'log_accuracy_table',\n",
       " 'log_confusion_matrix',\n",
       " 'log_image',\n",
       " 'log_list',\n",
       " 'log_predictions',\n",
       " 'log_residuals',\n",
       " 'log_row',\n",
       " 'log_table',\n",
       " 'name',\n",
       " 'number',\n",
       " 'parent',\n",
       " 'portal_url',\n",
       " 'properties',\n",
       " 'register_model',\n",
       " 'remove_tags',\n",
       " 'restore_snapshot',\n",
       " 'set_tags',\n",
       " 'start',\n",
       " 'status',\n",
       " 'submit_child',\n",
       " 'tag',\n",
       " 'tags',\n",
       " 'take_snapshot',\n",
       " 'type',\n",
       " 'upload_file',\n",
       " 'upload_files',\n",
       " 'upload_folder',\n",
       " 'wait_for_completion']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.download_file('outputs/train_ds', output_file_path='./train_dstmp.csv')\n",
    "!head ./cleantmp.csv\n",
    "run.download_file('outputs/valid_ds', output_file_path='./valid_dstmp.csv')\n",
    "!head ./cleantmp.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ref = def_blob_store.upload_files(\n",
    "    ['./train_dstmp.csv'],\n",
    "    target_path='tmp/train.csv',\n",
    "    overwrite=True)\n",
    "train_ref.data_reference_name = \"train_data\"\n",
    "\n",
    "valid_ref = def_blob_store.upload_files(\n",
    "    ['./valid_dstmp.csv'],\n",
    "    target_path='tmp/valid.csv',\n",
    "    overwrite=True)\n",
    "valid_ref.data_reference_name = \"valid_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_est = Estimator(source_directory='.', entry_script='./pipeline_steps/train.py',\n",
    "                script_params= {\"--dataset\": \"train_data\",\n",
    "                                \"--model\": \"model.pkl\"},\n",
    "                inputs=[train_ref],\n",
    "                compute_target='local',\n",
    "                use_docker=False\n",
    "               )\n",
    "\n",
    "run = experiment.submit(split_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name='test_model',\n",
    "                           tags={'test': 'test'},\n",
    "                           model_path='outputs/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_est = Estimator(source_directory='.', entry_script='./pipeline_steps/eval.py',\n",
    "                script_params= {\"--dataset\": \"valid_data\",\n",
    "                                \"--model\": \"model.pkl\"},\n",
    "                inputs=[valid_ref],\n",
    "                compute_target='local',\n",
    "                use_docker=False\n",
    "               )\n",
    "\n",
    "run = experiment.submit(eval_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
