{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "from azureml.core import ScriptRunConfig, RunConfiguration, Experiment\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.data.data_reference import DataReference\n",
    "#from azureml.data.dataset_consumption_config import DatasetConsumptionConfig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "def_file_store = Datastore(ws, \"workspacefilestore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing clean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'use_docker' parameter will be deprecated. Please use 'environment_definition' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: CleanTest_1585823600_183b9301\n",
      "Web View: https://ml.azure.com/experiments/CleanTest/runs/CleanTest_1585823600_183b9301?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 669\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ clean.py ] with arguments: ['--input', 'annonces_ds', '--output', 'cleantest']\n",
      "After variable expansion, calling script [ clean.py ] with arguments: ['--input', 'annonces_ds', '--output', 'cleantest']\n",
      "\n",
      "/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py:722: UserWarning: Your pandas and pyarrow versions are incompatible. Please install pyarrow>=0.12.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install azureml-dataprep[pandas].\n",
      "  warnings.warn('Your pandas and pyarrow versions are incompatible. '\n",
      "/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/python3.6/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 669\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.9992814064025879 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: CleanTest_1585823600_183b9301\n",
      "Web View: https://ml.azure.com/experiments/CleanTest/runs/CleanTest_1585823600_183b9301?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'CleanTest_1585823600_183b9301',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-04-02T10:33:21.356673Z',\n",
       " 'endTimeUtc': '2020-04-02T10:34:42.11558Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '187c48e4-92c4-4d8b-9222-b9ec642f942d'},\n",
       " 'inputDatasets': [{'dataset': {'id': '5a88c2bd-5165-485b-a81f-bc8290270b5a'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'annonces_ds', 'mechanism': 'Direct'}}],\n",
       " 'runDefinition': {'script': 'clean.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input', 'annonces_ds', '--output', 'cleantest'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'annonces_ds': {'dataLocation': {'dataset': {'id': '5a88c2bd-5165-485b-a81f-bc8290270b5a'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'annonces_ds',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment CleanTest Environment',\n",
       "   'version': 'Autosave_2020-04-02T07:45:21Z_0ac19a9a',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}],\n",
       "     'name': 'azureml_da3e97fcb51801118b8e80207f3e01ad'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585823600_183b9301/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=oV%2FPbvCYRNm6Kic1JFgG2c1ZaB05WsSNQxIJhbQxHrg%3D&st=2020-04-02T10%3A22%3A19Z&se=2020-04-02T18%3A32%3A19Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585823600_183b9301/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=Y5NLt8Vgw0Eijei6jUiiQtf9UR8DQBL2xYK3bWFMmCE%3D&st=2020-04-02T10%3A22%3A19Z&se=2020-04-02T18%3A32%3A19Z&sp=r',\n",
       "  'logs/azureml/669_azureml.log': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585823600_183b9301/logs/azureml/669_azureml.log?sv=2019-02-02&sr=b&sig=nWSn0%2F%2FA1RYy1XJbiG6l9wSJRLQ81JuvSmadStzU5gY%3D&st=2020-04-02T10%3A22%3A19Z&se=2020-04-02T18%3A32%3A19Z&sp=r'}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(ws, name='annonces_ds')\n",
    "experiment = Experiment(ws, \"CleanTest\")\n",
    "\n",
    "clean_est = Estimator(source_directory='./pipeline_steps', entry_script='clean.py',\n",
    "                script_params= {\"--input\": 'annonces_ds', \"--output\": 'cleantest'},\n",
    "                inputs=[dataset.as_named_input('annonces_ds')],\n",
    "                compute_target='local',\n",
    "                use_docker=False\n",
    "               )\n",
    "\n",
    "run = experiment.submit(clean_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",idannonce,typedebien,codepostal,idtypechauffage,idtypecuisine,si_balcon,nb_chambres,nb_pieces,si_sdbain,si_sdEau,etage,prix,surface,dpeC,date\r\n",
      "0,154680523,Appartement,33000,gaz collectif,,0.0,2.0,3,1,0,2.0,843,60.0,0.0,2019-03-28 15:30:41.565724000\r\n",
      "1,155037587,Appartement,33700,individuel électrique radiateur,aucune,0.0,0.0,1,0,0,2.0,512,21.35,195.0,2019-03-28 19:37:48.081944028\r\n",
      "2,152350643,Appartement,33140,,,1.0,2.0,3,0,0,3.0,859,69.48,138.0,2019-03-28 23:44:54.598164056\r\n",
      "3,155513075,Appartement,33400,,,1.0,1.0,2,0,0,3.0,695,47.25,162.0,2019-03-29 03:52:01.114384084\r\n",
      "4,155025785,Appartement,33000,gaz collectif,,0.0,2.0,3,1,0,4.0,814,68.0,0.0,2019-03-29 07:59:07.630604112\r\n",
      "5,155551059,Appartement,33700,individuel électrique,américaine,1.0,2.0,3,1,0,0.0,756,65.51,0.0,2019-03-29 12:06:14.146824141\r\n",
      "7,154854333,Appartement,33600,,équipée,0.0,1.0,2,0,1,0.0,720,36.0,0.0,2019-03-29 20:20:27.179264197\r\n",
      "8,155325225,Appartement,33600,individuel,,1.0,1.0,2,0,1,1.0,564,37.01,167.0,2019-03-30 00:27:33.695484225\r\n",
      "10,153924329,Appartement,33150,individuel gaz radiateur,équipée,0.0,2.0,3,1,0,0.0,763,73.09,45.0,2019-03-30 08:41:46.727924282\r\n"
     ]
    }
   ],
   "source": [
    "run.download_file('outputs/cleantest', output_file_path='./cleantmp.csv')\n",
    "!head ./cleantmp.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./cleantmp.csv\n",
      "Uploaded ./cleantmp.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_clean_data"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ref = def_blob_store.upload_files(\n",
    "    ['./cleantmp.csv'],\n",
    "    target_path='tmp/clean.csv',\n",
    "    overwrite=True)\n",
    "clean_ref.data_reference_name = \"clean_data\"\n",
    "clean_ref.mode = 'download' # 'download'\n",
    "clean_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_paths = [(def_blob_store, 'tmp/clean.csv')]\n",
    "clean_ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)\n",
    "# # clean_ds = clean_ds.register(workspace=ws,\n",
    "# #                            name='clean_ds',\n",
    "# #                            description='annonces data clean')\n",
    "# clean_ds = DatasetConsumptionConfig('clean_ds', clan_ds, mode='direct', path_on_compute=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'use_docker' parameter will be deprecated. Please use 'environment_definition' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: CleanTest_1585827071_4c6083c2\n",
      "Web View: https://ml.azure.com/experiments/CleanTest/runs/CleanTest_1585827071_4c6083c2?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 1962\n",
      "Running: ['/bin/bash', '/tmp/azureml_runs/CleanTest_1585827071_4c6083c2/azureml-environment-setup/conda_env_checker.sh']\n",
      "Found materialized conda environment in: /home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad\n",
      "\n",
      "\n",
      "Running: ['/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/bin/python', 'azureml-setup/run_script.py', '/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/bin/python', 'azureml-setup/context_manager_injector.py', '-i', 'ProjectPythonPath:context_managers.ProjectPythonPath', '-i', 'RunHistory:context_managers.RunHistory', '-i', 'TrackUserError:context_managers.TrackUserError', 'split.py', '--dataset', 'clean_data', '--train', 'train_ds', '--valid', 'valid_ds', '--trainsize', '400', '--validsize', '100']\n",
      "Logging experiment running status in history service.\n",
      "Streaming log file azureml-logs/70_driver_log.txt\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 1975\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ split.py ] with arguments: ['--dataset', 'clean_data', '--train', 'train_ds', '--valid', 'valid_ds', '--trainsize', '400', '--validsize', '100']\n",
      "After variable expansion, calling script [ split.py ] with arguments: ['--dataset', 'clean_data', '--train', 'train_ds', '--valid', 'valid_ds', '--trainsize', '400', '--validsize', '100']\n",
      "\n",
      "/home/jovyan/.azureml/envs/azureml_da3e97fcb51801118b8e80207f3e01ad/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py:722: UserWarning: Your pandas and pyarrow versions are incompatible. Please install pyarrow>=0.12.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install azureml-dataprep[pandas].\n",
      "  warnings.warn('Your pandas and pyarrow versions are incompatible. '\n",
      "Dataset:  TabularDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', './data/annonces_timestamp.csv')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\",\n",
      "    \"SetColumnTypes\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"5a88c2bd-5165-485b-a81f-bc8290270b5a\",\n",
      "    \"name\": \"annonces_ds\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"annonces data full\",\n",
      "    \"workspace\": \"Workspace.create(name='RealEstatePG2', subscription_id='68bdd703-8837-469c-80bd-bfb35f3b886f', resource_group='ProjectGroup2')\"\n",
      "  }\n",
      "}\n",
      "Train name:        idannonce      typedebien  ...    id                           date\n",
      "1627  157221383     Appartement  ...  2086  2020-01-01 20:16:23.455709896\n",
      "1628  157567239     Appartement  ...  2088  2020-01-02 00:23:29.971929924\n",
      "1629  157709887     Appartement  ...  2089  2020-01-02 04:30:36.488149952\n",
      "1630  157856745     Appartement  ...  2090  2020-01-02 08:37:43.004369980\n",
      "1631  157828247     Appartement  ...  2091  2020-01-02 12:44:49.520590008\n",
      "...         ...             ...  ...   ...                            ...\n",
      "2022  157630987     Appartement  ...  2592  2020-03-09 15:04:17.362621036\n",
      "2023  157341595     Appartement  ...  2593  2020-03-09 19:11:23.878841064\n",
      "2024  157401873  Maison / Villa  ...  2594  2020-03-09 23:18:30.395061092\n",
      "2025  156303415     Appartement  ...  2596  2020-03-10 03:25:36.911281120\n",
      "2026  157445831     Appartement  ...  2598  2020-03-10 07:32:43.427501148\n",
      "\n",
      "[400 rows x 21 columns]\n",
      "Valid name:        idannonce   typedebien  ...    id                           date\n",
      "2027  156734605  Appartement  ...  2601  2020-03-10 11:39:49.943721176\n",
      "2028  156502551  Appartement  ...  2602  2020-03-10 15:46:56.459941208\n",
      "2029  157120569  Appartement  ...  2603  2020-03-10 19:54:02.976161236\n",
      "2030  157813801  Appartement  ...  2604  2020-03-11 00:01:09.492381264\n",
      "2031  156846605  Appartement  ...  2605  2020-03-11 04:08:16.008601292\n",
      "...         ...          ...  ...   ...                            ...\n",
      "2122  155718489  Appartement  ...  2705  2020-03-26 18:55:08.984623860\n",
      "2123  156806825  Appartement  ...  2706  2020-03-26 23:02:15.500843888\n",
      "2124  157079279  Appartement  ...  2707  2020-03-27 03:09:22.017063916\n",
      "2125  157882541  Appartement  ...  2708  2020-03-27 07:16:28.533283944\n",
      "2126  157274675  Appartement  ...  2709  2020-03-27 11:23:35.049503972\n",
      "\n",
      "[100 rows x 21 columns]\n",
      "Train size:  400\n",
      "Valid size:  100\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 1975\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.8779144287109375 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: CleanTest_1585827071_4c6083c2\n",
      "Web View: https://ml.azure.com/experiments/CleanTest/runs/CleanTest_1585827071_4c6083c2?wsid=/subscriptions/68bdd703-8837-469c-80bd-bfb35f3b886f/resourcegroups/ProjectGroup2/workspaces/RealEstatePG2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'CleanTest_1585827071_4c6083c2',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-04-02T11:31:13.3316Z',\n",
       " 'endTimeUtc': '2020-04-02T11:32:33.615598Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'd15f9fe6-61d6-4004-b6d8-796d9f34f37b'},\n",
       " 'inputDatasets': [{'dataset': {'id': '5a88c2bd-5165-485b-a81f-bc8290270b5a'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'clean_data', 'mechanism': 'Direct'}}],\n",
       " 'runDefinition': {'script': 'split.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--dataset',\n",
       "   'clean_data',\n",
       "   '--train',\n",
       "   'train_ds',\n",
       "   '--valid',\n",
       "   'valid_ds',\n",
       "   '--trainsize',\n",
       "   '400',\n",
       "   '--validsize',\n",
       "   '100'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'clean_data': {'dataLocation': {'dataset': {'id': '5a88c2bd-5165-485b-a81f-bc8290270b5a'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'clean_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment CleanTest Environment',\n",
       "   'version': 'Autosave_2020-04-02T07:45:21Z_0ac19a9a',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}],\n",
       "     'name': 'azureml_da3e97fcb51801118b8e80207f3e01ad'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585827071_4c6083c2/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=MLzFGDcljsCQSiW8t8vWGTCUIiU6JRL%2F%2Bga%2B5bCiJgM%3D&st=2020-04-02T11%3A20%3A11Z&se=2020-04-02T19%3A30%3A11Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585827071_4c6083c2/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=13fFFGu6qTcWO%2FsbWRCQgMtHFQ1%2BhAzkCP1nPlJRPHI%3D&st=2020-04-02T11%3A20%3A11Z&se=2020-04-02T19%3A30%3A11Z&sp=r',\n",
       "  'logs/azureml/1975_azureml.log': 'https://realestastoragef42c16f2b.blob.core.windows.net/azureml/ExperimentRun/dcid.CleanTest_1585827071_4c6083c2/logs/azureml/1975_azureml.log?sv=2019-02-02&sr=b&sig=XoX%2BtGTadbWe3x7XRppLlNXNylgOONw1j87V81aHhG4%3D&st=2020-04-02T11%3A20%3A11Z&se=2020-04-02T19%3A30%3A11Z&sp=r'}}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_est = Estimator(source_directory='./pipeline_steps',\n",
    "                      entry_script='split.py',\n",
    "                      script_params= {\"--dataset\": \"clean_data\",\n",
    "                                      \"--train\": \"train_ds\",\n",
    "                                      \"--valid\": \"valid_ds\",\n",
    "                                      \"--trainsize\": 400,\n",
    "                                      \"--validsize\": 100},\n",
    "                      #inputs=[clean_ref],\n",
    "                      inputs=[dataset.as_named_input('clean_data')],\n",
    "                      compute_target='local',\n",
    "                      use_docker=False\n",
    "                     )\n",
    "\n",
    "run = experiment.submit(split_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",idannonce,typedebien,codepostal,idtypechauffage,idtypecuisine,si_balcon,nb_chambres,nb_pieces,si_sdbain,si_sdEau,etage,prix,surface,dpeC,date\n",
      "0,154680523,Appartement,33000,gaz collectif,,0.0,2.0,3,1,0,2.0,843,60.0,0.0,2019-03-28 15:30:41.565724000\n",
      "1,155037587,Appartement,33700,individuel électrique radiateur,aucune,0.0,0.0,1,0,0,2.0,512,21.35,195.0,2019-03-28 19:37:48.081944028\n",
      "2,152350643,Appartement,33140,,,1.0,2.0,3,0,0,3.0,859,69.48,138.0,2019-03-28 23:44:54.598164056\n",
      "3,155513075,Appartement,33400,,,1.0,1.0,2,0,0,3.0,695,47.25,162.0,2019-03-29 03:52:01.114384084\n",
      "4,155025785,Appartement,33000,gaz collectif,,0.0,2.0,3,1,0,4.0,814,68.0,0.0,2019-03-29 07:59:07.630604112\n",
      "5,155551059,Appartement,33700,individuel électrique,américaine,1.0,2.0,3,1,0,0.0,756,65.51,0.0,2019-03-29 12:06:14.146824141\n",
      "7,154854333,Appartement,33600,,équipée,0.0,1.0,2,0,1,0.0,720,36.0,0.0,2019-03-29 20:20:27.179264197\n",
      "8,155325225,Appartement,33600,individuel,,1.0,1.0,2,0,1,1.0,564,37.01,167.0,2019-03-30 00:27:33.695484225\n",
      "10,153924329,Appartement,33150,individuel gaz radiateur,équipée,0.0,2.0,3,1,0,0.0,763,73.09,45.0,2019-03-30 08:41:46.727924282\n",
      ",idannonce,typedebien,codepostal,idtypechauffage,idtypecuisine,si_balcon,nb_chambres,nb_pieces,si_sdbain,si_sdEau,etage,prix,surface,dpeC,date\n",
      "0,154680523,Appartement,33000,gaz collectif,,0.0,2.0,3,1,0,2.0,843,60.0,0.0,2019-03-28 15:30:41.565724000\n",
      "1,155037587,Appartement,33700,individuel électrique radiateur,aucune,0.0,0.0,1,0,0,2.0,512,21.35,195.0,2019-03-28 19:37:48.081944028\n",
      "2,152350643,Appartement,33140,,,1.0,2.0,3,0,0,3.0,859,69.48,138.0,2019-03-28 23:44:54.598164056\n",
      "3,155513075,Appartement,33400,,,1.0,1.0,2,0,0,3.0,695,47.25,162.0,2019-03-29 03:52:01.114384084\n",
      "4,155025785,Appartement,33000,gaz collectif,,0.0,2.0,3,1,0,4.0,814,68.0,0.0,2019-03-29 07:59:07.630604112\n",
      "5,155551059,Appartement,33700,individuel électrique,américaine,1.0,2.0,3,1,0,0.0,756,65.51,0.0,2019-03-29 12:06:14.146824141\n",
      "7,154854333,Appartement,33600,,équipée,0.0,1.0,2,0,1,0.0,720,36.0,0.0,2019-03-29 20:20:27.179264197\n",
      "8,155325225,Appartement,33600,individuel,,1.0,1.0,2,0,1,1.0,564,37.01,167.0,2019-03-30 00:27:33.695484225\n",
      "10,153924329,Appartement,33150,individuel gaz radiateur,équipée,0.0,2.0,3,1,0,0.0,763,73.09,45.0,2019-03-30 08:41:46.727924282\n"
     ]
    }
   ],
   "source": [
    "run.download_file('outputs/train_ds', output_file_path='./train_dstmp.csv')\n",
    "!head ./cleantmp.csv\n",
    "run.download_file('outputs/valid_ds', output_file_path='./valid_dstmp.csv')\n",
    "!head ./cleantmp.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./train_dstmp.csv\n",
      "Uploaded ./train_dstmp.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./valid_dstmp.csv\n",
      "Uploaded ./valid_dstmp.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "train_ref = def_blob_store.upload_files(\n",
    "    ['./train_dstmp.csv'],\n",
    "    target_path='tmp/train.csv',\n",
    "    overwrite=True)\n",
    "train_ref.data_reference_name = \"train_data\"\n",
    "train_ref.mode = 'download'\n",
    "\n",
    "valid_ref = def_blob_store.upload_files(\n",
    "    ['./valid_dstmp.csv'],\n",
    "    target_path='tmp/valid.csv',\n",
    "    overwrite=True)\n",
    "valid_ref.data_reference_name = \"valid_data\"\n",
    "valid_ref.mode = 'download'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_paths = [(def_blob_store, 'tmp/train.csv')]\n",
    "train_ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)\n",
    "\n",
    "datastore_paths = [(def_blob_store, 'tmp/valid.csv')]\n",
    "valid_ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_est = Estimator(source_directory='.', entry_script='./pipeline_steps/train.py',\n",
    "                script_params= {\"--dataset\": \"train_data\",\n",
    "                                \"--model\": \"model.pkl\"},\n",
    "                inputs=[train_ref],\n",
    "                #inputs=[dataset.as_named_input('clean_data')],\n",
    "                compute_target='local',\n",
    "                use_docker=False\n",
    "               )\n",
    "\n",
    "run = experiment.submit(split_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name='test_model',\n",
    "                           tags={'test': 'test'},\n",
    "                           model_path='outputs/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_est = Estimator(source_directory='.', entry_script='./pipeline_steps/eval.py',\n",
    "                script_params= {\"--dataset\": \"valid_data\",\n",
    "                                \"--model\": \"model.pkl\"},\n",
    "                inputs=[valid_ref],\n",
    "                compute_target='local',\n",
    "                use_docker=False\n",
    "               )\n",
    "\n",
    "run = experiment.submit(eval_est)\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
